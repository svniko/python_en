{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working With Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture we're going to talk about pattern matching in strings using regular expressions. Regular\n",
    "expressions, or regexes, are written in a condensed formatting language. In general, you can think of a\n",
    "regular expression as a pattern which you give to a regex processor with some source data. The processor then\n",
    "parses that source data using that pattern, and returns chunks of text back to the a data scientist or \n",
    "programmer for further manipulation. There's really three main reasons you would want to do this - to check\n",
    "whether a pattern exists within some source data, to get all instances of a complex pattern from some source\n",
    "data, or to clean your source data using a pattern generally through string splitting. Regexes are not\n",
    "trivial, but they are a foundational technique for data cleaning in data science applications, and a solid\n",
    "understanding of regexs will help you quickly and efficiently manipulate text data for further data science\n",
    "application.\n",
    "\n",
    "Now, you could teach a whole course on regular expressions alone, especially if you wanted to demystify how\n",
    "the regex parsing engine works and efficient mechanisms for parsing text. In this lecture I want to give you\n",
    "basic understanding of how regex works - enough knowledge that, with a little directed sleuthing, you'll be\n",
    "able to make sense of the regex patterns you see others use, and you can build up your practical knowledge of\n",
    "how to use regexes to improve your data cleaning. By the end of this lecture, you will understand the basics\n",
    "of regular expressions, how to define patterns for matching, how to apply these patterns to strings, and how\n",
    "to use the results of those patterns in data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"The impossible could not have happened, therefore the impossible must be possible in spite of appearances.\"\n",
    "\n",
    "len(text1) # The length of text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = text1.split(' ') # Return a list of the words in text2, separating by ' '.\n",
    "\n",
    "len(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'impossible',\n",
       " 'could',\n",
       " 'not',\n",
       " 'have',\n",
       " 'happened,',\n",
       " 'therefore',\n",
       " 'the',\n",
       " 'impossible',\n",
       " 'must',\n",
       " 'be',\n",
       " 'possible',\n",
       " 'in',\n",
       " 'spite',\n",
       " 'of',\n",
       " 'appearances.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "List comprehension allows us to find specific words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['impossible',\n",
       " 'could',\n",
       " 'have',\n",
       " 'happened,',\n",
       " 'therefore',\n",
       " 'impossible',\n",
       " 'must',\n",
       " 'possible',\n",
       " 'spite',\n",
       " 'appearances.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in text2 if len(w) > 3] # Words that are greater than 3 letters long in text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in text2 if w.istitle()] # Capitalized words in text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'impossible',\n",
       " 'have',\n",
       " 'therefore',\n",
       " 'the',\n",
       " 'impossible',\n",
       " 'be',\n",
       " 'possible',\n",
       " 'spite']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in text2 if w.endswith('e')] # Words in text2 that end in 'e'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We can find unique words using `set()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = 'To be or not to be'\n",
    "text4 = text3.split(' ')\n",
    "\n",
    "len(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'To', 'be', 'not', 'or', 'to'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([w.lower() for w in text4])) # .lower converts the string to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'be', 'not', 'or', 'to'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([w.lower() for w in text4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing free-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"The',\n",
       " 'impossible',\n",
       " 'could',\n",
       " 'not',\n",
       " 'have',\n",
       " 'happened,',\n",
       " 'therefore',\n",
       " 'the',\n",
       " 'impossible',\n",
       " 'must',\n",
       " 'be',\n",
       " 'possible',\n",
       " 'in',\n",
       " 'spite',\n",
       " 'of',\n",
       " 'appearances\"',\n",
       " '#impossible',\n",
       " '@',\n",
       " 'https://www.goodreads.com/author/quotes/123715.Agatha_Christie']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5 = '\"The impossible could not have happened, therefore the impossible must be possible in spite of appearances\" \\\n",
    "#impossible @ https://www.goodreads.com/author/quotes/123715.Agatha_Christie'\n",
    "text6 = text5.split(' ')\n",
    "\n",
    "text6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some word comparison functions\n",
    "  * s.startswith(t)\n",
    "  * s.endswith(t)\n",
    "  * t in s\n",
    "  * s.isupper(); s.islower(); s.istitle()\n",
    "  * s.isalpha(); s.isdigit(); s.isalnum()\n",
    "  \n",
    "The full list of Python String Methods you can find for example here - https://docs.python.org/2.5/lib/string-methods.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Finding hastags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#impossible']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in text6 if w.startswith('#')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Finding callouts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in text6 if w.startswith('@')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text7 = '@UN @UN_Women \"Ethics are built right into the ideals and objectives of the United Nations\" \\\n",
    "#UNSG @ NY Society for Ethical Culture bit.ly/2guVelr'\n",
    "text8 = text7.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "We can use regular expressions to help us with more complex parsing. \n",
    "\n",
    "For example `'@[A-Za-z0-9_]+'` will return all words that: \n",
    "* start with `'@'` and are followed by at least one: \n",
    "* capital letter (`'A-Z'`)\n",
    "* lowercase letter (`'a-z'`) \n",
    "* number (`'0-9'`)\n",
    "* or underscore (`'_'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re # import re - a module that provides support for regular expressions\n",
    "\n",
    "[w for w in text8 if re.search('@[A-Za-z0-9_]+', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll import the re module, which is where python stores regular expression libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " There are several main processing functions in re that you might use. The first, `match()` checks for a match\n",
    " that is at the beginning of the string and returns a boolean. Similarly, `search()`, checks for a match\n",
    " anywhere in the string, and returns a boolean.\n",
    "\n",
    " Lets create some text for an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wonderful!\n"
     ]
    }
   ],
   "source": [
    "text = \"This is a good day.\"\n",
    "\n",
    "# Now, lets see if it's a good day or not:\n",
    "if re.search(\"good\", text): # the first parameter here is the pattern\n",
    "    print(\"Wonderful!\")\n",
    "else:\n",
    "    print(\"Alas :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alas :(\n"
     ]
    }
   ],
   "source": [
    "if re.match('day',text):# checks for a  match that is at the beginning of the string\n",
    "    print(\"Wonderful!\")\n",
    "else:\n",
    "    print(\"Alas :(\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wonderful!\n"
     ]
    }
   ],
   "source": [
    "if re.match('This',text): \n",
    "    print(\"Wonderful!\")\n",
    "else:\n",
    "    print(\"Alas :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.match('day',text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to checking for conditionals, we can segment a string. The work that regex does here is called\n",
    "**tokenizing**, where the string is separated into substrings based on patterns. Tokenizing is a core activity in the natural language processing, which we won't talk much about here but that you will study in the future\n",
    "\n",
    "The ``findall()`` and ``split()`` functions will parse the string for us and return chunks. Lets try and example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', ' works hard. ', ' gets good grades. Our student ', ' is succesful.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Mary works hard. Mary gets good grades. Our student Mary is succesful.\"\n",
    "\n",
    "# This is a bit of a fabricated example, but lets split this on all instances of Mary\n",
    "re.split(\"Mary\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that split has returned an empty string, followed by a number of statements about Mary, all as\n",
    "elements of a list. If we wanted to count how many times we have talked about Mary, we could use `findall()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary', 'Mary', 'Mary']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"Mary\", text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we've seen that `.search()` looks for some pattern and returns a boolean, that `.split()` will use a\n",
    "pattern for creating a list of substrings, and that `.findall()` will look for a pattern and pull out all\n",
    "occurences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how the python regex API works, lets talk about more complex patterns. The regex\n",
    "specification standard defines a markup language to describe patterns in text. Lets start with anchors.\n",
    "Anchors specify the start and/or the end of the string that you are trying to match. The caret character ``^``\n",
    "means start and the dollar sign character ``$`` means end. If you put ``^`` before a string, it means that the text\n",
    "the regex processor retrieves must start with the string you specify. For ending, you have to put the ``$``\n",
    "character after the string, it means that the text Regex retrieves must end with the string you specify.\n",
    "\n",
    "Here's an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 4), match='Mary'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Mary works diligently. Mary gets good grades. Our student Mary is succesful.\"\n",
    "\n",
    "# Lets see if this begins with Mary\n",
    "re.search(\"^Mary\",text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that `re.search()` actually returned to us a new object, called `re.Match object`. An `re.Match object`\n",
    "always has a boolean value of `True`, as something was found, so you can always evaluate it in an `if` statement\n",
    "as we did earlier. The rendering of the match object also tells you what pattern was matched, in this case\n",
    " the word 'Mary', and the location the match was in, as the span."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patterns and Character Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk more about patterns and start with character classes. Let's create a string of a single learners'\n",
    "grades over a semester in one course across all of their assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 'B', 'B']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades=\"ACAAAABCBCBAA\"\n",
    "\n",
    "# If we want to answer the question \"How many B's were in the grade list?\" we would just use B\n",
    "re.findall(\"B\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to count the number of A's or B's in the list, we can't use \"AB\" since this is used to match\n",
    "all A's followed immediately by a B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AB']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"AB\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we put the characters A and B inside square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'A', 'A']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"[AB]\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called the set operator. You can also include a range of characters, which are ordered\n",
    "alphanumerically. For instance, if we want to refer to all lower case letters we could use [a-z]. Lets build\n",
    "a simple regex to parse out all instances where this student receive an A followed by a B or a C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AC', 'AB']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"[A][B-C]\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Notice how the [AB] pattern describes a set of possible characters which could be either (A OR B), while the\n",
    "[A][B-C] pattern denoted two sets of characters which must have been matched back to back. You can write\n",
    "this pattern by using the pipe operator, which means OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AC', 'AB']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"AB|AC\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the caret with the set operator to negate our results. For instance, if we want to parse out only\n",
    "the grades which were not A's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C', 'B', 'C', 'B', 'C', 'B']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"[^A]\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note this carefully - the caret was previously matched to the beginning of a string as an anchor point, but\n",
    "inside of the set operator the caret, and the other special characters we will be talking about, lose their\n",
    "meaning. This can be a bit confusing. What do you think the result would be of this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"^[^A]\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"[A]$\",grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'A']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"^A|[AB]$\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's an empty list, because the regex says that we want to match any value at the beginning of the string\n",
    "which is not an A. Our string though starts with an A, so there is no match found. And remember when you are\n",
    "using the set operator you are doing character-based matching. So you are matching individual characters in\n",
    "an OR method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we've talked about anchors and matching to the beginning and end of patterns. And we've talked about\n",
    "characters and using sets with the `[]` notation. We've also talked about character negation, and how the pipe\n",
    "`|` character allows us to `or` operations. Lets move on to quantifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantifiers are the number of times you want a pattern to be matched in order to match. The most basic\n",
    "quantifier is expressed as `e{m,n}`, where `e` is the expression or character we are matching,` m `is the minimum\n",
    "number of times you want it to matched, and ` n` is the maximum number of times the item could be matched.\n",
    "\n",
    "Let's use these grades as an example. How many times has this student been on a back-to-back A's streak?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAAA', 'AA']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"A{2,10}\",grades) # we'll use 2 as our min, but ten as our max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that there were two streaks, one where the student had four A's, and one where they had only two\n",
    "A's\n",
    "\n",
    "We might try and do this using single values and just repeating the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AA', 'AA']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"A{1,1}A{1,1}\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is different than the first example. The first pattern is looking for any combination\n",
    "of two A's up to ten A's in a row. So it sees four A's as a single streak. The second pattern is looking for\n",
    "two A's back to back, so it sees two A's followed immediately by two more A's. We say that the regex\n",
    "processor begins at the start of the string and consumes variables which match patterns as it does.\n",
    "\n",
    "It's important to note that the regex quantifier syntax does not allow you to deviate from the {m,n}\n",
    "pattern. In particular, if you have an extra space in between the braces you'll get an empty result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AA', 'AA']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"A{2,2}\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as we have already seen, if we don't include a quantifier then the default is {1,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AA', 'AA']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"AA\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you just have one number in the braces, it's considered to be both m and n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AA', 'AA', 'AA']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"A{2}\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this, we could find a decreasing trend in a student's grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAAABC']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"A{1,10}B{1,10}C{1,10}\",grades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that's a bit of a hack, because we included a maximum that was just arbitrarily large. There are three \n",
    "other quantifiers that are used as short hand, an asterix `*` to match 0 or more times, a question mark `?` to\n",
    "match 0 or 1 times, or a `+` plus sign to match one or more times. Lets look at a more complex example,\n",
    "and load some data scraped from wikipedia (https://en.wikipedia.org/wiki/Python_(programming_language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'History[edit]\\n\\nPython was conceived in the late 1980s[34] by Guido van Rossum at Centrum Wiskunde & Informatica (CWI) in the Netherlands as a successor to the ABC programming language, which was inspired by SETL),[35] capable of exception handling and interfacing with the Amoeba operating system.[8] Its implementation began in December 1989.[36] Van Rossum shouldered sole responsibility for the project, as the lead developer, until 12 July 2018, when he announced his \"permanent vacation\" from his responsibilities as Python\\'s Benevolent Dictator For Life, a title the Python community bestowed upon him to reflect his long-term commitment as the project\\'s chief decision-maker.[37] He now shares his leadership as a member of a five-person steering council.[38][39][40] In January 2019, active Python core developers elected Brett Cannon, Nick Coghlan, Barry Warsaw, Carol Willing and Van Rossum to a five-member \"Steering Council\" to lead the project.[41] Guido van Rossum has since then withdrawn his nomination for the 2020 Steering council.[42]\\nPython 2.0 was released on 16 October 2000 with many major new features, including a cycle-detecting garbage collector and support for Unicode.[43]\\nPython 3.0 was released on 3 December 2008. It was a major revision of the language that is not completely backward-compatible.[44] Many of its major features were backported to Python 2.6.x[45] and 2.7.x version series. Releases of Python 3 include the 2to3 utility, which automates (at least partially) the translation of Python 2 code to Python 3.[46]\\nPython 2.7\\'s end-of-life date was initially set at 2015 then postponed to 2020 out of concern that a large body of existing code could not easily be forward-ported to Python 3.[47][48] No more security patches or other improvements will be released for it.[49][50] With Python 2\\'s end-of-life, only Python 3.6.x[51] and later are supported.\\nDesign philosophy and features[edit]\\nPython is a multi-paradigm programming language. Object-oriented programming and structured programming are fully supported, and many of its features support functional programming and aspect-oriented programming (including by metaprogramming[52] and metaobjects (magic methods)).[53] Many other paradigms are supported via extensions, including design by contract[54][55] and logic programming.[56]\\nPython uses dynamic typing and a combination of reference counting and a cycle-detecting garbage collector for memory management.[57] It also features dynamic name resolution (late binding), which binds method and variable names during program execution.\\nPython\\'s design offers some support for functional programming in the Lisp tradition. It has filter, map, and reduce functions; list comprehensions, dictionaries, sets, and generator expressions.[58] The standard library has two modules (itertools and functools) that implement functional tools borrowed from Haskell and Standard ML.[59]\\nThe language\\'s core philosophy is summarized in the document The Zen of Python (PEP 20), which includes aphorisms such as:[60]\\n* Beautiful is better than ugly.\\n* Explicit is better than implicit.\\n* Simple is better than complex.\\n* Complex is better than complicated.\\n* Readability counts.\\nRather than having all of its functionality built into its core, Python was designed to be highly extensible. This compact modularity has made it particularly popular as a means of adding programmable interfaces to existing applications. Van Rossum\\'s vision of a small core language with a large standard library and easily extensible interpreter stemmed from his frustrations with ABC, which espoused the opposite approach.[34]\\nPython strives for a simpler, less-cluttered syntax and grammar while giving developers a choice in their coding methodology. In contrast to Perl\\'s \"there is more than one way to do it\" motto, Python embraces a \"there should be one?and preferably only one?obvious way to do it\" design philosophy.[60] Alex Martelli, a Fellow at the Python Software Foundation and Python book author, writes that \"To describe something as \\'clever\\' is not considered a compliment in the Python culture.\"[61]\\nPython\\'s developers strive to avoid premature optimization, and reject patches to non-critical parts of the CPython reference implementation that would offer marginal increases in speed at the cost of clarity.[62] When speed is important, a Python programmer can move time-critical functions to extension modules written in languages such as C, or use PyPy, a just-in-time compiler. Cython is also available, which translates a Python script into C and makes direct C-level API calls into the Python interpreter.\\nAn important goal of Python\\'s developers is keeping it fun to use. This is reflected in the language\\'s name?a tribute to the British comedy group Monty Python[63]?and in occasionally playful approaches to tutorials and reference materials, such as examples that refer to spam and eggs (from a famous Monty Python sketch) instead of the standard foo and bar.[64][65]\\nA common neologism in the Python community is pythonic, which can have a wide range of meanings related to program style. To say that code is pythonic is to say that it uses Python idioms well, that it is natural or shows fluency in the language, that it conforms with Python\\'s minimalist philosophy and emphasis on readability. In contrast, code that is difficult to understand or reads like a rough transcription from another programming language is called unpythonic.\\nUsers and admirers of Python, especially those considered knowledgeable or experienced, are often referred to as Pythonistas.[66][67]\\nSyntax and semantics[edit]\\nMain article: Python syntax and semantics\\nPython is meant to be an easily readable language. Its formatting is visually uncluttered, and it often uses English keywords where other languages use punctuation. Unlike many other languages, it does not use curly brackets to delimit blocks, and semicolons after statements are optional. It has fewer syntactic exceptions and special cases than C or Pascal.[68]\\nIndentation[edit]\\nMain article: Python syntax and semantics ? Indentation\\nPython uses whitespace indentation, rather than curly brackets or keywords, to delimit blocks. An increase in indentation comes after certain statements; a decrease in indentation signifies the end of the current block.[69] Thus, the program\\'s visual structure accurately represents the program\\'s semantic structure.[1] This feature is sometimes termed the off-side rule, which some other languages share, but in most languages indentation doesn\\'t have any semantic meaning.\\nStatements and control flow[edit]\\nPython\\'s statements include (among others):\\n* The assignment statement (token \\'=\\', the equals sign). This operates differently than in traditional imperative programming languages, and this fundamental mechanism (including the nature of Python\\'s version of variables) illuminates many other features of the language. Assignment in C, e.g., x = 2, translates to \"typed variable name x receives a copy of numeric value 2\". The (right-hand) value is copied into an allocated storage location for which the (left-hand) variable name is the symbolic address. The memory allocated to the variable is large enough (potentially quite large) for the declared type. In the simplest case of Python assignment, using the same example, x = 2, translates to \"(generic) name x receives a reference to a separate, dynamically allocated object of numeric (int) type of value 2.\" This is termed binding the name to the object. Since the name\\'s storage location doesn\\'t contain the indicated value, it is improper to call it a variable. Names may be subsequently rebound at any time to objects of greatly varying types, including strings, procedures, complex objects with data and methods, etc. Successive assignments of a common value to multiple names, e.g., x = 2; y = 2; z = 2 result in allocating storage to (at most) three names and one numeric object, to which all three names are bound. Since a name is a generic reference holder it is unreasonable to associate a fixed data type with it. However at a given time a name will be bound to some object, which will have a type; thus there is dynamic typing.\\n* The if statement, which conditionally executes a block of code, along with else and elif (a contraction of else-if).\\n* The for statement, which iterates over an iterable object, capturing each element to a local variable for use by the attached block.\\n* The while statement, which executes a block of code as long as its condition is true.\\n* The try statement, which allows exceptions raised in its attached code block to be caught and handled by except clauses; it also ensures that clean-up code in a finally block will always be run regardless of how the block exits.\\n* The raise statement, used to raise a specified exception or re-raise a caught exception.\\n* The class statement, which executes a block of code and attaches its local namespace to a class, for use in object-oriented programming.\\n* The def statement, which defines a function or method.\\n* The with statement, from Python 2.5 released in September 2006,[70] which encloses a code block within a context manager (for example, acquiring a lock before the block of code is run and releasing the lock afterwards, or opening a file and then closing it), allowing Resource Acquisition Is Initialization (RAII)-like behavior and replaces a common try/finally idiom.[71]\\n* The break statement, exits from the loop.\\n* The continue statement, skips this iteration and continues with the next item.\\n* The pass statement, which serves as a NOP. It is syntactically needed to create an empty code block.\\n* The assert statement, used during debugging to check for conditions that ought to apply.\\n* The yield statement, which returns a value from a generator function. From Python 2.5, yield is also an operator. This form is used to implement coroutines.\\n* The return statement, used to return a value from a function.\\n* The import statement, which is used to import modules whose functions or variables can be used in the current program. There are three ways of using import: import <module name> [as <alias>] or from <module name> import * or from <module name> import <definition 1> [as <alias 1>], <definition 2> [as <alias 2>], ....\\n* The print statement was changed to the print() function in Python 3.\\nPython does not support tail call optimization or first-class continuations, and, according to Guido van Rossum, it never will.[72][73] However, better support for coroutine-like functionality is provided in 2.5, by extending Python\\'s generators.[74] Before 2.5, generators were lazy iterators; information was passed unidirectionally out of the generator. From Python 2.5, it is possible to pass information back into a generator function, and from Python 3.3, the information can be passed through multiple stack levels.[75]\\nExpressions[edit]\\nSome Python expressions are similar to languages such as C and Java, while some are not:\\n* Addition, subtraction, and multiplication are the same, but the behavior of division differs. There are two types of divisions in Python. They are floor division (or integer division) // and floating point/division.[76] Python also added the ** operator for exponentiation.\\n* From Python 3.5, the new @ infix operator was introduced. It is intended to be used by libraries such as NumPy for matrix multiplication.[77][78]\\n* From Python 3.8, the syntax :=, called the \\'walrus operator\\' was introduced. It assigns values to variables as part of a larger expression.[79]\\n\\n'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"Python.txt\",\"r\") as file:\n",
    "    # we'll read that into a variable called wiki\n",
    "    wiki=file.read()\n",
    "# and lets print that variable out to the screen\n",
    "wiki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Scanning through this document one of the things we notice is that the headers all have the words [edit] behind them, followed by a newline character. So if we wanted to get a list of all of the headers in this\n",
    "article we could do so using `re.findall`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['History[edit]',\n",
       " 'features[edit]',\n",
       " 'semantics[edit]',\n",
       " 'Indentation[edit]',\n",
       " 'flow[edit]',\n",
       " 'Expressions[edit]']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"[a-zA-Z]{1,100}\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that didn't quite work. It got all of the headers, but only the last word of the header, and it really\n",
    "was quite clunky. Lets iteratively improve this. First, we can use `\\w` to match any letter, including digits\n",
    "and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['History[edit]',\n",
       " 'features[edit]',\n",
       " 'semantics[edit]',\n",
       " 'Indentation[edit]',\n",
       " 'flow[edit]',\n",
       " 'Expressions[edit]']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"[\\w]{1,100}\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is something new. `\\w ` is a metacharacter, and indicates a special pattern of any letter or digit. There\n",
    "are actually a number of different metacharacters listed in the documentation. For instance, `\\s` matches any\n",
    "whitespace character.\n",
    "\n",
    "Next, there are three other quantifiers we can use which shorten up the curly brace syntax. We can use an\n",
    "asterix `*` to match 0 or more times, so let's try that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['History[edit]',\n",
       " 'features[edit]',\n",
       " 'semantics[edit]',\n",
       " 'Indentation[edit]',\n",
       " 'flow[edit]',\n",
       " 'Expressions[edit]']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"[\\w]*\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have shortened the regex, let's improve it a little bit. We can add in a spaces using the space\n",
    "character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['History[edit]',\n",
       " 'Design philosophy and features[edit]',\n",
       " 'Syntax and semantics[edit]',\n",
       " 'Indentation[edit]',\n",
       " 'Statements and control flow[edit]',\n",
       " 'Expressions[edit]']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"[\\w ]*\\[edit\\]\",wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so this gets us the list of section titles in the wikipedia page! You can now create a list of titles by\n",
    "iterating through this and applying another regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History\n",
      "Design philosophy and features\n",
      "Syntax and semantics\n",
      "Indentation\n",
      "Statements and control flow\n",
      "Expressions\n"
     ]
    }
   ],
   "source": [
    "for title in re.findall(\"[\\w ]*\\[edit\\]\",wiki):\n",
    "    # Now we will take that intermediate result and split on the square bracket [ just taking the first result\n",
    "    print(re.split(\"[\\[]\",title)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this works, but it's a bit of a pain. To this point we have been talking about a regex as a single\n",
    "pattern which is matched. But, you can actually match different patterns, called groups, at the same time,\n",
    "and then refer to the groups you want. To group patterns together you use parentheses, which is actually\n",
    " pretty natural. Lets rewrite our `findall` using groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('History', '[edit]'),\n",
       " ('Design philosophy and features', '[edit]'),\n",
       " ('Syntax and semantics', '[edit]'),\n",
       " ('Indentation', '[edit]'),\n",
       " ('Statements and control flow', '[edit]'),\n",
       " ('Expressions', '[edit]')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(\"([\\w ]*)(\\[edit\\])\",wiki)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice - we see that the python `re` module breaks out the result by group. We can actually refer to groups by\n",
    "number as well with the match objects that are returned. But, how do we get back a list of match objects?\n",
    "Thus far we've seen that ``findall()`` returns strings, and ``search()`` and ``match()`` return individual ``Match objects``. But what do we do if we want a list of Match objects? In this case, we use the function ``finditer()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('History', '[edit]')\n",
      "('Design philosophy and features', '[edit]')\n",
      "('Syntax and semantics', '[edit]')\n",
      "('Indentation', '[edit]')\n",
      "('Statements and control flow', '[edit]')\n",
      "('Expressions', '[edit]')\n"
     ]
    }
   ],
   "source": [
    "for item in re.finditer(\"([\\w ]*)(\\[edit\\])\",wiki):\n",
    "    print(item.groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see here that the ``groups()`` method returns a tuple of the group. We can get an individual group using\n",
    "`group(number)`, where `group(0)` is the whole match, and each other number is the portion of the match we are\n",
    "interested in. In this case, we want `group(1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History[edit]\n",
      "Design philosophy and features[edit]\n",
      "Syntax and semantics[edit]\n",
      "Indentation[edit]\n",
      "Statements and control flow[edit]\n",
      "Expressions[edit]\n"
     ]
    }
   ],
   "source": [
    "for item in re.finditer(\"([\\w ]*)(\\[edit\\])\",wiki):\n",
    "    print(item.group()) #by default number=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more piece to regex is labeling or naming groups. In the previous example I showed you how you can use the position of the group. But giving them a label and looking at the results as a dictionary is pretty useful. For that we use the syntax `(?P<name>)`, where the parethesis starts the group, the `?P` indicates that this is an extension to basic regexes, and `<name>` is the dictionary key we want to use wrapped in `<>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History\n",
      "Design philosophy and features\n",
      "Syntax and semantics\n",
      "Indentation\n",
      "Statements and control flow\n",
      "Expressions\n"
     ]
    }
   ],
   "source": [
    "for item in re.finditer(\"(?P<title>[\\w ]*)(?P<edit_link>\\[edit\\])\",wiki):\n",
    "    # We can get the dictionary returned for the item with .groupdict()\n",
    "    print(item.groupdict()['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'History', 'edit_link': '[edit]'}\n",
      "{'title': 'Design philosophy and features', 'edit_link': '[edit]'}\n",
      "{'title': 'Syntax and semantics', 'edit_link': '[edit]'}\n",
      "{'title': 'Indentation', 'edit_link': '[edit]'}\n",
      "{'title': 'Statements and control flow', 'edit_link': '[edit]'}\n",
      "{'title': 'Expressions', 'edit_link': '[edit]'}\n"
     ]
    }
   ],
   "source": [
    " # Lets see all dictionry\n",
    "for item in re.finditer(\"(?P<title>[\\w ]*)(?P<edit_link>\\[edit\\])\",wiki):\n",
    "    print(item.groupdict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can print out the whole dictionary for the item too, and see that the last string is still\n",
    "in there. Here's the dictionary kept for the last match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Expressions', 'edit_link': '[edit]'}\n"
     ]
    }
   ],
   "source": [
    "print(item.groupdict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ok, we have seen how we can match individual character patterns with `[]`, how we can group matches together\n",
    " using `()`, and how we can use quantifiers such as `*`, `?`, or `{mn}` to describe patterns, the `\\w`, which standards for any word character. There are a number of short hands which are used with regexes for different kinds of characters, including:\n",
    " a `. `for any single character which is not a newline a` \\d` for any digit and` \\s` for any whitespace character, like `spaces` and `tabs`.\n",
    "There are more, and a full list can be found in the python documentation for regexes - https://docs.python.org/3/library/re.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorized String Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One strength of Python is its relative ease in handling and manipulating string data.\n",
    "Pandas builds on this and provides a comprehensive set of *vectorized string operations* that become an essential piece of the type of munging required when working with (read: cleaning up) real-world data.\n",
    "In this section, we'll walk through some of the Pandas string operations, and then take a look at using them to partially clean up a very messy dataset of recipes collected from the Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducing Pandas String Operations\n",
    "\n",
    "We saw in previous sections how tools like NumPy and Pandas generalize arithmetic operations so that we can easily and quickly perform the same operation on many array elements. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  6, 10, 14, 22, 26])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([2, 3, 5, 7, 11, 13])\n",
    "x * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This *vectorization* of operations simplifies the syntax of operating on arrays of data: we no longer have to worry about the size or shape of the array, but just about what operation we want done.\n",
    "For arrays of strings, NumPy does not provide such simple access, and thus you're stuck using a more verbose loop syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Peter', 'Paul', 'Mary', 'Guido']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ['peter', 'Paul', 'MARY', 'gUIDO']\n",
    "#data.apitalize() - give an error\n",
    "[s.capitalize() for s in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is perhaps sufficient to work with some data, but it will break if there are any missing values.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'capitalize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-3b0264c38d59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'peter'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Paul'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MARY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gUIDO'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-63-3b0264c38d59>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'peter'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Paul'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MARY'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'gUIDO'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcapitalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'capitalize'"
     ]
    }
   ],
   "source": [
    "data = ['peter', 'Paul', None, 'MARY', 'gUIDO']\n",
    "[s.capitalize() for s in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas includes features to address both this need for vectorized string operations and for correctly handling missing data via the ``str`` attribute of Pandas Series and Index objects containing strings.\n",
    "So, for example, suppose we create a Pandas Series with this data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    peter\n",
       "1     Paul\n",
       "2     None\n",
       "3     MARY\n",
       "4    gUIDO\n",
       "dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "names = pd.Series(data)\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call a single method that will capitalize all the entries, while skipping over any missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Peter\n",
       "1     Paul\n",
       "2     None\n",
       "3     Mary\n",
       "4    Guido\n",
       "dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.str.capitalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using tab completion on this ``str`` attribute will list all the vectorized string methods available to Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables of Pandas String Methods\n",
    "\n",
    "If you have a good understanding of string manipulation in Python, most of Pandas string syntax is intuitive enough that it's probably sufficient to just list a table of available methods; we will start with that here, before diving deeper into a few of the subtleties.\n",
    "The examples in this section use the following series of names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectives = pd.Series(['James Bond', 'Johnny English', 'Sherlock Holmes',\n",
    "                   'Hercule Poirot', 'Jane Marple', 'Jules Maigret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods similar to Python string methods\n",
    "Nearly all Python's built-in string methods are mirrored by a Pandas vectorized string method. Here is a list of Pandas ``str`` methods that mirror Python string methods:\n",
    "\n",
    "|             |                  |                  |                  |\n",
    "|-------------|------------------|------------------|------------------|\n",
    "|``len()``    | ``lower()``      | ``translate()``  | ``islower()``    | \n",
    "|``ljust()``  | ``upper()``      | ``startswith()`` | ``isupper()``    | \n",
    "|``rjust()``  | ``find()``       | ``endswith()``   | ``isnumeric()``  | \n",
    "|``center()`` | ``rfind()``      | ``isalnum()``    | ``isdecimal()``  | \n",
    "|``zfill()``  | ``index()``      | ``isalpha()``    | ``split()``      | \n",
    "|``strip()``  | ``rindex()``     | ``isdigit()``    | ``rsplit()``     | \n",
    "|``rstrip()`` | ``capitalize()`` | ``isspace()``    | ``partition()``  | \n",
    "|``lstrip()`` |  ``swapcase()``  |  ``istitle()``   | ``rpartition()`` |\n",
    "\n",
    "Notice that these have various return values. Some, like ``lower()``, return a series of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         james bond\n",
       "1     johnny english\n",
       "2    sherlock holmes\n",
       "3     hercule poirot\n",
       "4        jane marple\n",
       "5      jules maigret\n",
       "dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectives.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But some others return numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    14\n",
       "2    15\n",
       "3    14\n",
       "4    11\n",
       "5    13\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectives.str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or Boolean values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2     True\n",
       "3    False\n",
       "4    False\n",
       "5    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectives.str.startswith('S')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still others return lists or other compound values for each element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [James, Bond]\n",
       "1     [Johnny, English]\n",
       "2    [Sherlock, Holmes]\n",
       "3     [Hercule, Poirot]\n",
       "4        [Jane, Marple]\n",
       "5      [Jules, Maigret]\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectives.str.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods using regular expressions\n",
    "\n",
    "In addition, there are several methods that accept regular expressions to examine the content of each string element, and follow some of the API conventions of Python's built-in ``re`` module:\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| ``match()`` | Call ``re.match()`` on each element, returning a boolean. |\n",
    "| ``extract()`` | Call ``re.match()`` on each element, returning matched groups as strings.|\n",
    "| ``findall()`` | Call ``re.findall()`` on each element |\n",
    "| ``replace()`` | Replace occurrences of pattern with some other string|\n",
    "| ``contains()`` | Call ``re.search()`` on each element, returning a boolean |\n",
    "| ``count()`` | Count occurrences of pattern|\n",
    "| ``split()``   | Equivalent to ``str.split()``, but accepts regexps |\n",
    "| ``rsplit()`` | Equivalent to ``str.rsplit()``, but accepts regexps |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these, you can do a wide range of interesting operations.\n",
    "For example, we can extract the first name from each by asking for a contiguous group of characters at the beginning of each element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Johnny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sherlock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hercule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jules</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0     James\n",
       "1    Johnny\n",
       "2  Sherlock\n",
       "3   Hercule\n",
       "4      Jane\n",
       "5     Jules"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectives.str.extract('([A-Za-z]+)') #  or '(\\w+)'\n",
    "# also you may add parameter  'expand=False' to output a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>Bond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Johnny</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sherlock</td>\n",
       "      <td>Holmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hercule</td>\n",
       "      <td>Poirot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Marple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jules</td>\n",
       "      <td>Maigret</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0     James      Bond\n",
       "1    Johnny   English\n",
       "2  Sherlock    Holmes\n",
       "3   Hercule    Poirot\n",
       "4      Jane    Marple\n",
       "5     Jules   Maigret"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectives.str.extract('(\\w+)( \\w+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James</td>\n",
       "      <td>Bond</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Johnny</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sherlock</td>\n",
       "      <td>Holmes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hercule</td>\n",
       "      <td>Poirot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jane</td>\n",
       "      <td>Marple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jules</td>\n",
       "      <td>Maigret</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name last_name\n",
       "0     James      Bond\n",
       "1    Johnny   English\n",
       "2  Sherlock    Holmes\n",
       "3   Hercule    Poirot\n",
       "4      Jane    Marple\n",
       "5     Jules   Maigret"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectives.str.extract('(?P<name>\\w*)(?P<last_name> \\w+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can do something more complicated, like finding all names that start and end with a consonant, making use of the start-of-string (``^``) and end-of-string (``$``) regular expression characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [James Bond]\n",
       "1                   []\n",
       "2    [Sherlock Holmes]\n",
       "3     [Hercule Poirot]\n",
       "4                   []\n",
       "5      [Jules Maigret]\n",
       "dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectives.str.findall('^[^AEIOU]*[^aeiou]$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ability to concisely apply regular expressions across ``Series`` or ``Dataframe`` entries opens up many possibilities for analysis and cleaning of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous methods\n",
    "Finally, there are some miscellaneous methods that enable other convenient operations:\n",
    "\n",
    "| Method | Description |\n",
    "|--------|-------------|\n",
    "| ``get()`` | Index each element |\n",
    "| ``slice()`` | Slice each element|\n",
    "| ``slice_replace()`` | Replace slice in each element with passed value|\n",
    "| ``cat()``      | Concatenate strings|\n",
    "| ``repeat()`` | Repeat values |\n",
    "| ``normalize()`` | Return Unicode form of string |\n",
    "| ``pad()`` | Add whitespace to left, right, or both sides of strings|\n",
    "| ``wrap()`` | Split long strings into lines with length less than a given width|\n",
    "| ``join()`` | Join strings in each element of the Series with passed separator|\n",
    "| ``get_dummies()`` | extract dummy variables as a dataframe |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorized item access and slicing\n",
    "\n",
    "The ``get()`` and ``slice()`` operations, in particular, enable vectorized element access from each array.\n",
    "For example, we can get a slice of the first three characters of each array using ``str.slice(0, 3)``.\n",
    "Note that this behavior is also available through Python's normal indexing syntax–for example, ``df.str.slice(0, 3)`` is equivalent to ``df.str[0:3]``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Jam\n",
       "1    Joh\n",
       "2    She\n",
       "3    Her\n",
       "4    Jan\n",
       "5    Jul\n",
       "dtype: object"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectives.str.slice(0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "5    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectives.str.slice(0, 3) == detectives.str[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing via ``df.str.get(i)`` and ``df.str[i]`` is likewise similar.\n",
    "\n",
    "These ``get()`` and ``slice()`` methods also let you access elements of arrays returned by ``split()``.\n",
    "For example, to extract the last name of each entry, we can combine ``split()`` and ``get()``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Bond\n",
       "1    English\n",
       "2     Holmes\n",
       "3     Poirot\n",
       "4     Marple\n",
       "5    Maigret\n",
       "dtype: object"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectives.str.split().str.get(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indicator variables\n",
    "\n",
    "Another method that requires a bit of extra explanation is the ``get_dummies()`` method.\n",
    "This is useful when your data has a column containing some sort of coded indicator.\n",
    "For example, we might have a dataset that contains some categorial information, such as A=\"speaks French,\" B=\"born in the United Kingdom,\" C=\"likes cheese,\" D=\"likes Vesper Martini\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>James Bond</td>\n",
       "      <td>B|C|D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Johnny English</td>\n",
       "      <td>B|D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sherlock Holmes</td>\n",
       "      <td>B|C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hercule Poirot</td>\n",
       "      <td>A|C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jane Marple</td>\n",
       "      <td>B|C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jules Maigret</td>\n",
       "      <td>B|C|D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name   info\n",
       "0       James Bond  B|C|D\n",
       "1   Johnny English    B|D\n",
       "2  Sherlock Holmes    B|C\n",
       "3   Hercule Poirot    A|C\n",
       "4      Jane Marple    B|C\n",
       "5    Jules Maigret  B|C|D"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_detectives = pd.DataFrame({'name': detectives,\n",
    "                           'info': ['B|C|D', 'B|D', 'B|C',\n",
    "                                    'A|C', 'B|C', 'B|C|D']})\n",
    "full_detectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ``get_dummies()`` routine lets you quickly split-out these indicator variables into a ``DataFrame``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C  D\n",
       "0  0  1  1  1\n",
       "1  0  1  0  1\n",
       "2  0  1  1  0\n",
       "3  1  0  1  0\n",
       "4  0  1  1  0\n",
       "5  0  1  1  1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_detectives['info'].str.get_dummies('|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these operations as building blocks, you can construct an endless range of string processing procedures when cleaning your data.\n",
    "\n",
    "We won't dive further into these methods here, but I encourage you to read through [\"Working with Text Data\"](http://pandas.pydata.org/pandas-docs/stable/text.html) in the Pandas online documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture has been an overview of regular expressions, and really, we've just scratched the surface of what \n",
    "you can do. \n",
    "But, there are lots of great examples and reference guides on the web, including the python\n",
    "documentation for regex, and with these in hand you should be able to write concise and readable code which\n",
    "performs well too. Having basic regex literacy is a core skill for applied data scientists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.read_csv('D:\\Света\\\\Фреймворки пайтон\\dataframe\\\\titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerID</th>\n",
       "      <th>Name</th>\n",
       "      <th>PClass</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "      <th>SexCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Allen, Miss Elisabeth Walton</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>female</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Allison, Miss Helen Loraine</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Allison, Mr Hudson Joshua Creighton</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Allison, Mrs Hudson JC (Bessie Waldo Daniels)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Allison, Master Hudson Trevor</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>1309</td>\n",
       "      <td>Zakarian, Mr Artun</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>1310</td>\n",
       "      <td>Zakarian, Mr Maprieder</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>1311</td>\n",
       "      <td>Zenni, Mr Philip</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>1312</td>\n",
       "      <td>Lievens, Mr Rene</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>1313</td>\n",
       "      <td>Zimmerman, Leo</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1313 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PassengerID                                           Name  PClass  \\\n",
       "0               1                   Allen, Miss Elisabeth Walton     1.0   \n",
       "1               2                    Allison, Miss Helen Loraine     1.0   \n",
       "2               3            Allison, Mr Hudson Joshua Creighton     1.0   \n",
       "3               4  Allison, Mrs Hudson JC (Bessie Waldo Daniels)     1.0   \n",
       "4               5                  Allison, Master Hudson Trevor     1.0   \n",
       "...           ...                                            ...     ...   \n",
       "1308         1309                             Zakarian, Mr Artun     3.0   \n",
       "1309         1310                         Zakarian, Mr Maprieder     3.0   \n",
       "1310         1311                               Zenni, Mr Philip     3.0   \n",
       "1311         1312                               Lievens, Mr Rene     3.0   \n",
       "1312         1313                                 Zimmerman, Leo     3.0   \n",
       "\n",
       "        Age     Sex  Survived  SexCode  \n",
       "0     29.00  female         1        1  \n",
       "1      2.00  female         0        1  \n",
       "2     30.00    male         0        0  \n",
       "3     25.00  female         0        1  \n",
       "4      0.92    male         1        0  \n",
       "...     ...     ...       ...      ...  \n",
       "1308  27.00    male         0        0  \n",
       "1309  26.00    male         0        0  \n",
       "1310  22.00    male         0        0  \n",
       "1311  24.00    male         0        0  \n",
       "1312  29.00    male         0        0  \n",
       "\n",
       "[1313 rows x 7 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic['PClass'] = titanic['PClass'].str[0]\n",
    "titanic['PClass'] = pd.to_numeric(titanic['PClass'],errors = 'coerce')\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_fem = titanic[titanic['SexCode']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_name</th>\n",
       "      <th>title</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Elisabeth Walton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allison</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Helen Loraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Allison</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Hudson JC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Andrews</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Kornelia Theodosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Appleton</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Edward Dale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>Vestrom</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Hulda Amanda Adolfina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>Wilkes</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Ellen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Yasbeck</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Antoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>Zabour</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Hileni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>Zabour</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Tamini</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     last_name title                   name\n",
       "0        Allen  Miss       Elisabeth Walton\n",
       "1      Allison  Miss          Helen Loraine\n",
       "3      Allison   Mrs             Hudson JC \n",
       "6      Andrews  Miss     Kornelia Theodosia\n",
       "8     Appleton   Mrs           Edward Dale \n",
       "...        ...   ...                    ...\n",
       "1283   Vestrom  Miss  Hulda Amanda Adolfina\n",
       "1293    Wilkes   Mrs                  Ellen\n",
       "1304   Yasbeck   Mrs                 Antoni\n",
       "1306    Zabour  Miss                 Hileni\n",
       "1307    Zabour  Miss                 Tamini\n",
       "\n",
       "[462 rows x 3 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = titanic_fem['Name'].str.extract('(?P<last_name>\\w*), (?P<title>\\w*) (?P<name>[\\w ]*)')\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Miss', 'Mrs', 'Madame', 'Lady', 'Dr', 'the', 'Ms', nan, 'Mlle',\n",
       "       'Hilda', 'Jenny'], dtype=object)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names['title'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_name</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dr</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hilda</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jenny</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lady</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madame</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Miss</th>\n",
       "      <td>236</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mlle</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mrs</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ms</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        last_name  name\n",
       "title                  \n",
       "Dr              1     1\n",
       "Hilda           1     1\n",
       "Jenny           1     1\n",
       "Lady            1     1\n",
       "Madame          1     1\n",
       "Miss          236   236\n",
       "Mlle            1     1\n",
       "Mrs           200   200\n",
       "Ms             13    13\n",
       "the             1     1"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names.groupby(['title']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_name</th>\n",
       "      <th>title</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Rothes</td>\n",
       "      <td>the</td>\n",
       "      <td>Countess of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    last_name title          name\n",
       "214    Rothes   the  Countess of "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[names['title'] == 'the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
